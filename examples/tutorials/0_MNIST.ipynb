{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 0: **pcax**\n",
    "In this notebook, you will learn how to use pcax to build arbitrary predictive coding networks.\n",
    "Since the library is still in its early development, expect major syntax changes. You can keep coming back to this notebook to stay updated.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Importing dependencies\n",
    "Pcax is based on jax and optax, so we will need those.\n",
    "The library is divided in three modules:\n",
    "- *core*: defines the basic building blocks of pcax, unrelated to predictive coding itself. You normally will not need to touch this unless you need some rather custom behaviour.\n",
    "- *pc*: here lies all the predictive coding implementation, which will probably keep changing and being updated.\n",
    "- *nn*: simply contains the typical layers you could expect from a deep learning library, which are currently built as a wrap around *equinox* layers.\n",
    "- *utils*: various optional tools.\n",
    "\n",
    "Furthermore, pcax requires cuda>=11.4 and cudnn >= 8.4. On pssr2 they can be activate with the terminal command `source switch-cuda 11.7`.\n",
    "Unfortunately it seems to be necessary to repeat this for each jupyter cell (normally you just call it once when you create the terminal you'll work in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "# Core dependencies\n",
    "import jax\n",
    "import optax\n",
    "\n",
    "# pcax\n",
    "import pcax as px # same as import pcax.pc as px\n",
    "import pcax.nn as nn\n",
    "from pcax.core import _ # _ is the filter object, more about it later!\n",
    "from pcax.utils.data import TorchDataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will also use the following dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "import timeit\n",
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\" # remember this line if you are sharing the GPU with others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Defining a Model\n",
    "Defining a basic pcax model is very straightforward: simply interpone in the forward call a `px.Layer` between any two `nn.Link`s (the way we will call standard deep learning layers). To do so first define them in the `__init__`, no arguments are required for basic usage!\n",
    "\n",
    "In the `__init__`, we also define the activation function we are going to use and the specify we do not want to train the `x` of the last pc layer, since it will contain the label we want to train our network with (it is probably how you will structure most of the PCNs you will use). Note this model does not directly support inference on the inputs as there is no pc layer that stores the input `x` of the forward call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "\"\"\"\n",
    "A model is defined in a way that is similar to PyTorch. In particular:\n",
    "- we inherit from px.Module;\n",
    "- we define the activation functions, layers (i.e., pc layers) and links (i.e., standard layers), in the __init__ method; \n",
    "- ModuleList is necessary to define a list of layers/links;\n",
    "- we define the forward pass in the __call__ method.\n",
    "\"\"\"\n",
    "class Model(px.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, nm_layers=2) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.act_fn = jax.nn.tanh\n",
    "\n",
    "        \"\"\"\n",
    "        This is quite standard. We define the layers and links (one layer for each link).\n",
    "        \"\"\"\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.linear_h = nn.ModuleList(\n",
    "            [nn.Linear(hidden_dim, hidden_dim) for _ in range(nm_layers)]\n",
    "        )\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self.pc1 = px.Layer()\n",
    "        self.pc_h = nn.ModuleList([px.Layer() for _ in range(nm_layers)])\n",
    "        self.pc2 = px.Layer()\n",
    "\n",
    "        \"\"\"\n",
    "        We normally use the x of the last layer as the target, therefore we don't want to update it.\n",
    "        \"\"\"\n",
    "        self.pc2.x.frozen = True\n",
    "\n",
    "    \"\"\"\n",
    "    Here things are a bit different. __call__ accepts an optional target t (used during training),\n",
    "    which is used to set the x of the last layer.\n",
    "    \"\"\"\n",
    "    def __call__(self, x, t=None):\n",
    "        \"\"\"\n",
    "        !!! IMPORTANT !!!\n",
    "        Each (pc) layer contains a cache the stores the important intermediate values computed in the forward pass.\n",
    "        By default, these are the incoming activation (u), the node values (x) and the energy (e).\n",
    "        You can access them by using the [] operator, e.g., self.pc[\"x\"].\n",
    "        \"\"\"\n",
    "        x = self.pc1(self.act_fn(self.linear1(x)))[\"x\"]\n",
    "\n",
    "        for i in range(len(self.linear_h)):\n",
    "            x = self.pc_h[i](self.act_fn(self.linear_h[i](x)))[\"x\"]\n",
    "\n",
    "        x = self.pc2(self.linear2(x))[\"x\"]\n",
    "\n",
    "        if t is not None:\n",
    "            self.pc2[\"x\"] = t\n",
    "\n",
    "        \"\"\"\n",
    "        The output of the network is the activation received by the last layer (since its x is clamped to the label).\n",
    "        \"\"\"\n",
    "        return self.pc2[\"u\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the training parameters we are going to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"batch_size\": 256,\n",
    "    \"x_learning_rate\": 0.01,\n",
    "    \"w_learning_rate\": 1e-3,\n",
    "    \"num_epochs\": 4,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"input_dim\": 28 * 28,\n",
    "    \"output_dim\": 10,\n",
    "    \"seed\": 0,\n",
    "    \"T\": 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define the dataloaders we'll need to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This is all standard and uses PyTorch's datasets and dataloaders. We are assuming cuda is available to set the dataloaders' parameters.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "We'll train with the standard pc energy function, that is, the sum of the squared differences between the node values and the target.\n",
    "Therefore, we need to convert the targets to one-hot vectors.\n",
    "\"\"\"\n",
    "def one_hot(t, k):\n",
    "    return np.array(t[:, None] == np.arange(k), dtype=np.float32)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Used to convert the square 0-255 images to 0-1 float vectors.\n",
    "\"\"\"\n",
    "class FlattenAndCast:\n",
    "    def __call__(self, pic):\n",
    "        return np.ravel(np.array(pic, dtype=np.float32) / 255.0)\n",
    "\n",
    "\n",
    "train_dataset = MNIST(\n",
    "    \"/tmp/mnist/\",\n",
    "    transform=FlattenAndCast(),\n",
    "    download=True,\n",
    "    train=True,\n",
    ")\n",
    "train_dataloader = TorchDataloader(\n",
    "    train_dataset,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    num_workers=16,\n",
    "    shuffle=True,\n",
    "    persistent_workers=True,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = MNIST(\n",
    "    \"/tmp/mnist/\",\n",
    "    transform=FlattenAndCast(),\n",
    "    download=True,\n",
    "    train=False,\n",
    ")\n",
    "test_dataloader = TorchDataloader(\n",
    "    test_dataset,\n",
    "    batch_size=params[\"batch_size\"],\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    persistent_workers=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Where the fun begins\n",
    "As mentioned, pcax is based on jax, which is a functional framework. Consequently, in order to offer a simple object oriented interface to it, there are some compromises to be made and strict patterns to follow.\n",
    "\n",
    "(Note: pcax.core is basically an heavily modified version of *objax*, so if you're lost you may find it helpful to also look at that documentation.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we **have** to instantiate the model, this is because pcax relies on binding global variables to the local scope of each function in order to work. So we need to have a model to begin with, and it's structure should (of course there are exception) be fixed for the rest of the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(28 * 28, params[\"hidden_dim\"], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1: Defining a function\n",
    "Let's see how a function involving a `px.Module` is defined. We'll proceed step by step (so only the last version is the correct one).\n",
    "\n",
    "Consider the function `predict(x, t)` which simply calls the forward pass of the model (we need to pass the target `t` as well since it is needed during training; unfortunately for `binded` function, as for now, default arguments are not supported, so you'll have to manually pass `None` if `t` is not necessary).\n",
    "In normal settings, `predict` should look similar to the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, t):\n",
    "    return model(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**However**, since this function uses a `px.Module` (i.e., `model`), we need to *bind* it to the function (it cannot be passed as an argument and therefore needs to be in the global scope that's why we defined it above). There's not much too add, it needs to be done :P\n",
    "The syntax is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@px.bind(model)\n",
    "def predict(x, t):\n",
    "    return model(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is **batching** (aka **vectorization**). Jax (and therefore pcax) defines each computation on a tensor assuming it contains a single sample (that is, there is no batch dimension as it happens, for instance, in Pytorch). Therefore, if in the function above, `x` is supposed to be an array with shape [28x28,] (remember we are flattening the MNIST images inside the dataloader) and `t` an array with shape [10,] (remember we are one-hot encoding it). If we want `predict` to be able to work on batched input (i.e., `x` with shape [n, 28x28]), we need to *vectorize* the function such that the `predict` computation will be repeated along the batch dimension.\n",
    "\n",
    "We will use another decorator to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@px.vectorize(_(px.NodeVar), in_axis=(0, 0))\n",
    "@px.bind(model)\n",
    "def predict(x, t):\n",
    "    return model(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's ignore the first argument for a second and focus on `in_axis`: it is telling the function that both its inputs have to be batched along the 0th dimension, which means that now `predict` expects as inputs two arrays with shape [n, *] (in this case [n, 784] and [n, 10]). Similarly to the inputs, we have to specify if the outputs of the function will have an added \"batch\" dimension. In this case, `model` outputs a predictions for each `x`, so if `x` is batched, also the output will be. By default, `px.vectorize` assumes the decorated function has a single input to be batched, so we do not have to specify anything else for now.\n",
    "If an input does not have a batch dimensions but it is, instead, a constant value to be used for each `x`, you can pass `None` instead of `0` for that particular parameter.\n",
    "\n",
    "The first argument in `px.vectorize` specifies which tensors of the modules binded to the function (in this case only `model`) needs to have a batch dimension as well. Well, in predictive coding, those tensors are the ones representing the value nodes, so in 99% of the cases you will end up always using the same first parameter for `px.vectorize`. Recall that `_` is the filter object, then `_(px.NodeVar)` simply is saying all the `px.NodeVar` parameters inside the binded modules. Conveniently, `px.NodeVar` are exclusively the tensors used to represent the node values.\n",
    "\n",
    "Try yourself:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(Model).pc1(Layer).x': pcax.pc.variables.NodeVar(None, reduce=reduce_id),\n",
       " '(Model).pc_h(ModuleList)[0](Layer).x': pcax.pc.variables.NodeVar(None, reduce=reduce_id),\n",
       " '(Model).pc_h(ModuleList)[1](Layer).x': pcax.pc.variables.NodeVar(None, reduce=reduce_id),\n",
       " '(Model).pc2(Layer).x': pcax.pc.variables.NodeVar(None, reduce=reduce_id)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vars(_(px.NodeVar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If instead we want to select the remaining tensors of the model, which in this case are all the link weights, we can use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'(Model).linear1(Linear).nn.weight': pcax.core.structure.TrainVar(DeviceArray([[ 0.01229068,  0.01379374,  0.00090728, ..., -0.01822209,\n",
       "                0.03359856,  0.01654346],\n",
       "              [ 0.02093922, -0.01357643,  0.03248229, ...,  0.02490543,\n",
       "               -0.00358149, -0.02930153],\n",
       "              [ 0.02113941, -0.01080453,  0.00963924, ..., -0.00074164,\n",
       "               -0.00332546, -0.02536105],\n",
       "              ...,\n",
       "              [-0.00435486, -0.0348849 , -0.01562772, ...,  0.02979221,\n",
       "               -0.0200628 , -0.01586745],\n",
       "              [ 0.02002883, -0.02582436, -0.00198849, ...,  0.02906173,\n",
       "               -0.02739396, -0.01241719],\n",
       "              [-0.03521763,  0.0162226 ,  0.01106472, ..., -0.03282779,\n",
       "                0.01568388,  0.00918417]], dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear1(Linear).nn.bias': pcax.core.structure.TrainVar(DeviceArray([-1.05218217e-02, -3.13689187e-03, -1.56988334e-02,\n",
       "              -9.60610621e-03,  1.40408874e-02, -2.94154044e-02,\n",
       "              -6.35945797e-03,  7.11670890e-03, -2.81592458e-02,\n",
       "               2.36367248e-02,  2.88250782e-02, -2.57531330e-02,\n",
       "               3.11012529e-02,  9.06387344e-03,  2.51339525e-02,\n",
       "              -4.37843800e-03,  1.59651563e-02, -3.17406505e-02,\n",
       "              -1.24682616e-02, -3.50617617e-02,  2.13840269e-02,\n",
       "              -3.39662880e-02,  1.30784512e-02,  2.36490108e-02,\n",
       "              -1.91456079e-02, -3.32462303e-02,  1.93686932e-02,\n",
       "              -3.13815735e-02, -2.41504405e-02,  3.34549882e-02,\n",
       "              -2.59939283e-02, -2.91440263e-03, -2.58172601e-02,\n",
       "               2.02842467e-02, -2.44309157e-02, -2.93474644e-04,\n",
       "              -1.07272696e-02,  2.06897259e-02, -2.91326735e-02,\n",
       "               1.61416717e-02, -1.26635600e-02, -2.55885981e-02,\n",
       "              -3.15878987e-02,  9.29746404e-03,  1.18085220e-02,\n",
       "              -9.40394402e-03, -3.56269404e-02,  2.75248103e-02,\n",
       "               1.23216584e-02,  3.42746712e-02, -2.80013867e-02,\n",
       "              -2.00094506e-02,  3.07116099e-02, -1.99481770e-02,\n",
       "              -3.37789431e-02,  1.26767345e-02,  1.02544576e-03,\n",
       "              -2.74824947e-02, -2.30209082e-02, -1.69383641e-02,\n",
       "               2.77751349e-02, -2.29572579e-02,  1.19596310e-02,\n",
       "               5.62237948e-03,  2.09835358e-02,  2.32242085e-02,\n",
       "              -1.52789447e-02,  7.72270188e-03, -1.95006318e-02,\n",
       "              -1.68119762e-02, -3.19414996e-02,  2.36268640e-02,\n",
       "               3.26375775e-02,  3.32246162e-02, -1.85895916e-02,\n",
       "               2.55703926e-05,  7.73257762e-03,  1.29974745e-02,\n",
       "              -6.80647604e-03,  3.54859941e-02, -2.97652241e-02,\n",
       "               2.51475908e-02,  8.08387995e-03,  3.42684723e-02,\n",
       "               3.01236175e-02, -5.32217510e-03, -1.47585273e-02,\n",
       "              -2.48849392e-02, -4.39357758e-03, -1.67160816e-02,\n",
       "               2.46955603e-02,  2.62500383e-02,  1.60495564e-03,\n",
       "               4.78077680e-03,  2.83113532e-02, -2.60830969e-02,\n",
       "               1.87796354e-03, -2.41592713e-02, -1.12835169e-02,\n",
       "              -2.38130540e-02, -3.01788468e-02,  2.94582359e-02,\n",
       "              -1.46647170e-03, -3.07692550e-02,  2.66230702e-02,\n",
       "              -8.38422775e-03, -2.25237701e-02, -4.37603518e-03,\n",
       "               1.13277175e-02, -5.97424805e-05, -5.39329275e-03,\n",
       "              -2.51920745e-02,  1.81295872e-02, -7.69796595e-03,\n",
       "               3.17694359e-02,  1.03173777e-02, -9.03701037e-03,\n",
       "              -3.92224640e-04,  3.33643742e-02, -3.40668410e-02,\n",
       "              -2.48849913e-02, -2.56343335e-02, -3.42034623e-02,\n",
       "              -1.59897394e-02, -2.63505429e-02, -3.06548327e-02,\n",
       "               1.88547559e-02, -1.52488109e-02], dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear_h(ModuleList)[0](Linear).nn.weight': pcax.core.structure.TrainVar(DeviceArray([[-0.03838998,  0.03923199,  0.06443135, ...,  0.00887255,\n",
       "                0.04357516,  0.0115129 ],\n",
       "              [-0.07038675, -0.08056539,  0.07947307, ..., -0.07804914,\n",
       "               -0.00685388,  0.04511055],\n",
       "              [-0.05527534,  0.02679701, -0.02716329, ...,  0.04617236,\n",
       "                0.07244677,  0.06493863],\n",
       "              ...,\n",
       "              [ 0.05946667, -0.08817475,  0.0671033 , ...,  0.01106192,\n",
       "                0.06865019, -0.03907807],\n",
       "              [ 0.07958028, -0.04233242,  0.04327764, ..., -0.01917922,\n",
       "                0.02036892,  0.08159374],\n",
       "              [-0.04184021,  0.01736741,  0.05978122, ..., -0.07393977,\n",
       "               -0.03983906,  0.07852859]], dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear_h(ModuleList)[0](Linear).nn.bias': pcax.core.structure.TrainVar(DeviceArray([ 0.00659195,  0.02502067,  0.04336417, -0.05571149,\n",
       "              -0.02899195, -0.03274884,  0.01482138, -0.01372894,\n",
       "               0.02109599,  0.03776202, -0.00882839,  0.08539859,\n",
       "               0.02831577, -0.04856392,  0.0739041 , -0.07151517,\n",
       "               0.06727388,  0.02954955,  0.01078639, -0.01553893,\n",
       "               0.0833516 , -0.06142511, -0.08603738, -0.0803493 ,\n",
       "              -0.0797807 ,  0.08745065, -0.07420625,  0.04580579,\n",
       "              -0.01138671,  0.00436389,  0.01918777, -0.06589641,\n",
       "              -0.03452969,  0.08102626, -0.00919094,  0.04490513,\n",
       "              -0.08013707,  0.06194047, -0.05734538,  0.00172441,\n",
       "               0.00846123, -0.07016038, -0.04615398,  0.06857575,\n",
       "              -0.0839925 , -0.04311877,  0.03517517,  0.00234379,\n",
       "              -0.05972233,  0.07169943, -0.08469892,  0.00384461,\n",
       "              -0.05307331, -0.08324432,  0.00865641,  0.01834355,\n",
       "               0.00521561, -0.06753208, -0.03290609, -0.04580874,\n",
       "               0.00921408,  0.0730293 ,  0.07527257, -0.00058028,\n",
       "               0.0495295 , -0.04114957, -0.08755877,  0.03832095,\n",
       "              -0.03145014,  0.01408429,  0.01962049, -0.01562455,\n",
       "              -0.05330681, -0.04357291, -0.07172732,  0.04182387,\n",
       "               0.0422127 , -0.00743327,  0.05770076,  0.08183434,\n",
       "               0.01681461,  0.04089258, -0.05025832, -0.05887693,\n",
       "               0.08732622, -0.0695396 ,  0.05765488,  0.04363821,\n",
       "              -0.0738433 , -0.00755771, -0.02115849,  0.01302468,\n",
       "              -0.02065647,  0.01582661,  0.00770676,  0.04173725,\n",
       "               0.05158281,  0.05202349,  0.06201231,  0.04884071,\n",
       "              -0.04315742,  0.04140546, -0.05664111, -0.04373144,\n",
       "              -0.08106411,  0.03598333,  0.00526851, -0.00870855,\n",
       "               0.08673549,  0.07750196,  0.01241233, -0.03100261,\n",
       "               0.08109143, -0.02253778, -0.01516629, -0.0538179 ,\n",
       "               0.05707543, -0.05670433,  0.01961382,  0.01436248,\n",
       "              -0.00213775,  0.04726791,  0.08077504,  0.02295689,\n",
       "               0.04724967,  0.0247786 , -0.00625019, -0.04520047],            dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear_h(ModuleList)[1](Linear).nn.weight': pcax.core.structure.TrainVar(DeviceArray([[ 0.03417899, -0.06470662,  0.01215134, ...,  0.04303042,\n",
       "                0.05713136, -0.06584861],\n",
       "              [-0.08048274,  0.0004049 ,  0.07935738, ..., -0.02389625,\n",
       "               -0.06233475, -0.06309374],\n",
       "              [ 0.05249343,  0.01554173,  0.05825376, ..., -0.05195874,\n",
       "                0.03653628,  0.01188286],\n",
       "              ...,\n",
       "              [ 0.05254275,  0.03499862, -0.0182604 , ...,  0.04170235,\n",
       "               -0.05289737,  0.03271103],\n",
       "              [-0.07449999, -0.06700411, -0.02081706, ...,  0.04411409,\n",
       "               -0.0715295 , -0.07581727],\n",
       "              [ 0.06310921, -0.02537529, -0.04225795, ...,  0.04176255,\n",
       "                0.04720818, -0.0854414 ]], dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear_h(ModuleList)[1](Linear).nn.bias': pcax.core.structure.TrainVar(DeviceArray([ 7.01297000e-02,  6.50439635e-02,  5.12474850e-02,\n",
       "               1.14255473e-02,  4.72499207e-02, -4.82476689e-02,\n",
       "               1.49476975e-02, -7.37447441e-02, -9.30046290e-03,\n",
       "               6.45849481e-02, -2.83895694e-02,  8.11593607e-02,\n",
       "               8.16714838e-02, -5.33544756e-02, -5.29943071e-02,\n",
       "              -3.80609632e-02,  3.09960172e-02, -4.61055525e-02,\n",
       "               1.57582834e-02,  7.05356523e-02,  3.20085734e-02,\n",
       "              -6.96990415e-02, -1.80049837e-02,  4.23703566e-02,\n",
       "               8.63633305e-03,  1.89103186e-02, -5.94429225e-02,\n",
       "               1.79134607e-02,  4.85848561e-02,  5.19541278e-02,\n",
       "               3.05695906e-02,  1.64384097e-02, -4.95530665e-03,\n",
       "              -2.45925412e-02,  3.85417268e-02,  6.97031543e-02,\n",
       "              -8.04889128e-02,  1.24153197e-02,  2.95907557e-02,\n",
       "               5.67264184e-02, -4.37911227e-02,  5.62645420e-02,\n",
       "               6.03893325e-02, -7.67373592e-02, -4.82703634e-02,\n",
       "              -4.91696931e-02, -1.56966224e-02, -9.31913406e-03,\n",
       "              -1.56628639e-02, -5.61518855e-02, -8.03850144e-02,\n",
       "              -2.19215006e-02, -7.80065209e-02,  5.80053106e-02,\n",
       "               3.64539921e-02, -5.54539151e-02, -8.06684345e-02,\n",
       "              -5.33329360e-02,  4.32870314e-02, -7.87707716e-02,\n",
       "               2.68035606e-02, -5.53485267e-02, -8.14886391e-03,\n",
       "               6.51248619e-02,  2.75588557e-02, -3.41556370e-02,\n",
       "               1.91896707e-02, -7.23677576e-02,  4.59977910e-02,\n",
       "               1.36879906e-02, -6.83838949e-02,  8.26665983e-02,\n",
       "               1.55875906e-02, -5.05130403e-02, -1.06113926e-02,\n",
       "              -9.72644240e-03,  4.83375788e-03, -7.30448291e-02,\n",
       "              -8.58864039e-02,  5.43300733e-02, -2.14009881e-02,\n",
       "               7.43101612e-02,  3.42773125e-02,  5.14395460e-02,\n",
       "               1.89713091e-02, -1.07714310e-02, -4.34477329e-02,\n",
       "               7.19828531e-02, -9.45031643e-03, -3.51557173e-02,\n",
       "              -3.17695774e-02,  7.45627061e-02, -3.20734978e-02,\n",
       "               1.40554905e-02,  6.51834682e-02, -3.15211229e-02,\n",
       "               8.63048211e-02,  7.49993101e-02, -2.46813893e-03,\n",
       "               2.68071890e-05,  4.12532762e-02,  4.22737375e-02,\n",
       "              -6.52440786e-02, -6.12218678e-03, -8.53807926e-02,\n",
       "              -6.68633804e-02, -5.87390922e-02,  2.04509795e-02,\n",
       "              -4.73762304e-03,  8.14838484e-02,  5.52016273e-02,\n",
       "               7.46628717e-02,  8.78702179e-02, -8.31789523e-02,\n",
       "              -6.46692812e-02,  7.67998397e-04,  4.40093651e-02,\n",
       "               2.88454071e-02,  2.06369087e-02, -9.25633311e-03,\n",
       "               3.39194909e-02,  3.24341729e-02, -5.62438741e-02,\n",
       "              -1.08146891e-02,  2.21388787e-02,  4.44553122e-02,\n",
       "               2.92490721e-02, -1.61807835e-02], dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear2(Linear).nn.weight': pcax.core.structure.TrainVar(DeviceArray([[ 0.02466588, -0.07107343,  0.08567088, ...,  0.00266303,\n",
       "                0.04486375,  0.07863738],\n",
       "              [-0.06618838, -0.06876776,  0.01425868, ...,  0.06795085,\n",
       "               -0.08388544,  0.07668447],\n",
       "              [-0.0604539 , -0.06392863,  0.01519916, ..., -0.0660717 ,\n",
       "                0.02996904,  0.02899459],\n",
       "              ...,\n",
       "              [ 0.05129007,  0.04570002,  0.02057029, ..., -0.05227819,\n",
       "                0.02902395, -0.04747117],\n",
       "              [ 0.01466163, -0.0741225 , -0.06734017, ..., -0.08318269,\n",
       "                0.0323088 ,  0.04670895],\n",
       "              [ 0.03839829,  0.0564869 , -0.062555  , ..., -0.03395649,\n",
       "               -0.06967258,  0.0857246 ]], dtype=float32), reduce=reduce_none),\n",
       " '(Model).linear2(Linear).nn.bias': pcax.core.structure.TrainVar(DeviceArray([-0.01729323, -0.02672816,  0.01679782,  0.04279173,\n",
       "               0.05904032, -0.06045744,  0.0011316 ,  0.08765884,\n",
       "               0.03835525,  0.07243375], dtype=float32), reduce=reduce_none)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vars(_[px.TrainVar, -_(px.NodeVar)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular all trainable tensors (so weights and value nodes) are `px.TrainVar`s, while value nodes are also the subclass `px.NodeVar`.\n",
    "The filter object `_` has the following syntax:\n",
    "- `_(...)`: *or*\n",
    "- `_[...]`: *and*\n",
    "- `-_`: *not*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go to the next function we need: the loss function.  \n",
    "Similarly to how in Pytorch you compute the gradients from the loss by calling `loss.backward()`, here we compute the gradients by transforming the loss function such that is also output the gradients.\n",
    "\n",
    "In predictive coding, the standard loss function simply computes and returns the model's energy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@px.vectorize(_(px.NodeVar), in_axis=(0, 0), out_axis=(\"sum\",))\n",
    "@px.bind(model)\n",
    "def loss(x, t):\n",
    "    y = model(x)\n",
    "    return model.energy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe a few things:\n",
    "- we pass `t` and compute `y` as it's standard practice, however, here, they are not strictly necessary: we don't need the model's output to compute the error (as it is used already when computing the energy) and we assume that the target has already been set to the `x` of the last layer (so again it is already included in the energy computation).\n",
    "- The first two parameters of `px.vectorize` are the same of `predict`, however here we add a modifier for the output (notice that, even if we have a single output, `out_axis` is specified using a tuple). We use `\"sum\"` to specify that the output of the function should be the summed over the batch dimension. We do this because, as it happens in Pytorch, the loss must be a single floating point value (we don't use the mean since we want the total energy coming from each error node, not their average).\n",
    "- `model.energy` automatically computes the energy value for each layer in `model`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to define two different \"backward\" functions, one for the *x step* (in which we update the value nodes) and one for the *w step* (in which we update the weights). They are identical except for the fact that they compute gradients with respect of different elements.  \n",
    "`px.gradvalues` transform a function such that is outputs the gradients with respect to the specified variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We compute the gradients with respect to the node values that are not frozen.\n",
    "\"\"\"\n",
    "train_x = px.gradvalues(\n",
    "    _(px.NodeVar)(frozen=False), # _::(**kawrgs) is used to apply a filter, selecting all the variables with the specified properties\n",
    ")(loss)\n",
    "\n",
    "\"\"\"\n",
    "We compute the gradients with respect to the weights (every px.TrainVar that is not a px.NodeVar).\n",
    "\"\"\"\n",
    "train_w = px.gradvalues(\n",
    "    _[px.TrainVar, -_(px.NodeVar)],\n",
    ")(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This covers almost everything you need to do about defining a function the operates on one (or more) `px.Module`. Later we will see a couple of extra details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2: Optimizers\n",
    "In pcax (as it derives from Objax), optimizers are `px.Module`s as well, as a consequence they need to be treated similarly to how we used `model`. In particular, they must be bound to any function that uses them. So we need to define them beforehand in the global scope.  \n",
    "pcax offers a single `px.Optim` class that allows `px.Module`s to interact with most `optax` optimizers (the most common jax library for optimizers). As you can see from the following example, you simply have to specify which `optax` optimizer to use for which subset of the `px.Module` variables. In this case, similarly to how we defined the two loss functions, we defined an *x optimizer* and a *w optimizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "# dummy run to init the optimizer parameters\n",
    "with px.eval(model):\n",
    "    predict(np.zeros((params[\"batch_size\"], 28 * 28)), (None,) * params[\"batch_size\"])\n",
    "    optim_x = px.Optim(\n",
    "        optax.sgd(params[\"x_learning_rate\"]), model.vars(_(px.NodeVar)(frozen=False))\n",
    "    )\n",
    "    optim_w = px.Optim(\n",
    "        optax.adam(params[\"w_learning_rate\"]),\n",
    "        model.vars(_[px.TrainVar, -_(px.NodeVar)]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may ask yourself what are the first two lines for?\n",
    "\n",
    "It may be the case that your optimizers defines some parameters that are linked to the individual trainable parameter inside your model. For instance, you could choose to use `optax.adam` for `optim_x` (not recommended, for all we know you should stick with stateless optimizators for the value nodes). In this case, the optimizer needs to instantiate the `adam` parameters and, thus, it requires to know the shape of all the `px.NodeVar`s inside your model. However, if we do not run the model at least once, all the node values will be empty, since they are lazily created. Furthermore, the shape of the value nodes depends on the batch size (since, remember, we want different value nodes for each different input), so we need to perform a dummy run on a dummmy input with the same shape of the samples we are gonna train on to correctly initialize all the parameters inside the model. Only then we can safely create the two optimizers. (Note that this requires `batch_size` to be constant throught the program. To guarantee this, by default, the dataloaders have `drop_last=True`. Unless you know what you're doing, do not attempt to modify that.)\n",
    "\n",
    "It actually doesn't really matter what you pass as `x` and `t`, but only that their shape matches the one of the true input batches (but in this way you can see how you can pass `None` as the target of the predict function: it needs to be batched as well).\n",
    "\n",
    "This explains the `predict(...)` line. And the `with ...` line comes with it: `px.Module` uses an internal caching system to store intermediate values for later computations. `px.eval` takes care of clearing this cache. Therefore, every time you call `predict` (or, more precisely, you use `px.Module` to compute some values given an input, as it happens in the `__call__` function), you must enclose it under a `px.eval` manager (which also sets the module in eval mode), so that when you'll change the input, you are not gonna reuse the previously computed cached values. There's a similar context manager for training: `px.train`. They do slightly different things, but don't worry for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3: Training the model\n",
    "We are almost done. We have all the ingredients to train the model, we just need to assemble them in the training and evaluation functions. There's only one core concept to introduce: *jitting*. *Just In Time* compilation allows the program to get compiled and optimized (it's the reason we have so many constraints on how code should be written). We jit the computations executed on a single batch as we want to compile as much code as possible, and `train_on_batch` represents the single largest repeated operation occurring during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "@px.jit()\n",
    "@px.bind(model, optim_w=optim_w, optim_x=optim_x)\n",
    "def train_on_batch(x, y):\n",
    "    with px.eval(model):\n",
    "        y_hat, = predict(x, y)\n",
    "\n",
    "        for i in range(params[\"T\"]):\n",
    "            with px.train(model):\n",
    "                g, (v,) = train_x(x, y)\n",
    "                optim_x(g)\n",
    "\n",
    "        with px.train(model):\n",
    "            g, (v,) = train_w(x, y)\n",
    "            optim_w(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few remarks:\n",
    "- in `px.bind` we specify the keys for the optim arguments since optim_w and optim_x are the same type and the need a name to distinguish them.\n",
    "- this is the standard pc training procedure:\n",
    "    - we initialize the node values using `predict` (which by default uses forward initialization)\n",
    "    - we repeat the *x-update* step for `T` times and then we perform a single *w-update*.\n",
    "- `optim_*(g)` updates the node values/weights of the model, therefore all the computed cached values must be cleared. That's why we enclose each trainig operation in a `px.train`. The difference with `px.eval` (which encloses the whole function block) is that the latter also clears the node values themselves, such that, a new call of `train_on_batch` will populate them with the new forward values computed by calling `predict` on the new batch.\n",
    "- you can see that the values returned by `predict` and `train_*` (the first value returned by `train_*` are the computed gradients, and then there are the actual return values of the function) are all tuples, even if a single value is acutally returned by the orginal functions (before being transformed). Just something to keep in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the remaining functions. Nothing new here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "\"\"\"\n",
    "Again we jit the operation executed on each batch.\n",
    "\"\"\"\n",
    "@px.jit()\n",
    "@px.bind(model)\n",
    "def evaluate(x, y):\n",
    "    with px.eval(model):\n",
    "        y_hat, = predict(x, y) # remeber that 'predict' always returns a tuple\n",
    "\n",
    "    return (y_hat.argmax(-1) == y.argmax(-1)).mean()\n",
    "\n",
    "\n",
    "def epoch(dl):\n",
    "    for batch in dl:\n",
    "        x, y = batch\n",
    "        y = one_hot(y, 10)\n",
    "\n",
    "        train_on_batch(x, y)\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def test(dl):\n",
    "    accuracies = []\n",
    "    for batch in dl:\n",
    "        x, y = batch\n",
    "        y = one_hot(y, 10)\n",
    "\n",
    "        accuracies.append(evaluate(x, y))\n",
    "\n",
    "    return np.mean(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the main body:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched to CUDA 11.7.\n",
      "Compiling + Epoch 1 took 7.22816416202113 seconds\n",
      "An Epoch takes on average 0.9288925940054469 seconds\n",
      "Final Accuracy: 0.96324116\n"
     ]
    }
   ],
   "source": [
    "!source switch-cuda 11.7\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    t = timeit.timeit(lambda: epoch(train_dataloader), number=1)\n",
    "    print(\"Compiling + Epoch 1 took\", t, \"seconds\")\n",
    "\n",
    "    # Time of an epoch (without jitting)\n",
    "    t = timeit.timeit(lambda: epoch(train_dataloader), number=params[\"num_epochs\"]) / params[\"num_epochs\"]\n",
    "    print(\"An Epoch takes on average\", t, \"seconds\")\n",
    "\n",
    "    print(\"Final Accuracy:\", test(test_dataloader))\n",
    "\n",
    "    del train_dataloader\n",
    "    del test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is all right, you should get a final accuracy of ~96% and a training time of ~0.7 second per epoch. The training time is actually heavily bottlenecked by the data transfer between CPU and GPU, that's why we are using 16 workers in the dataloader. So depending on your configuration the final speed my change.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('pcax')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f4fd8fe68194e475a108d2c5b5ee1f820870a7a5127298df9ccb3dbbd47c3153"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
